from flask import Flask, request, jsonify
import cv2
from tensorflow.keras.models import load_model
import numpy as np

app = Flask(__name__)

# Load the pre-trained model
model = load_model('facial_expression_model.h5')
emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

@app.route('/predict', methods=['POST'])
def predict_stress():
    file = request.files['image']
    npimg = np.frombuffer(file.read(), np.uint8)
    img = cv2.imdecode(npimg, cv2.IMREAD_COLOR)
    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)

    emotions = []
    for (x, y, w, h) in faces:
        roi_gray = gray_frame[y:y+h, x:x+w]
        roi_gray = cv2.resize(roi_gray, (48, 48))
        roi_gray = np.expand_dims(np.expand_dims(roi_gray, -1), 0)
        prediction = model.predict(roi_gray)
        emotions.append(emotion_labels[np.argmax(prediction)])

    return jsonify({'emotions': emotions})

if __name__ == '__main__':
    app.run(port=5001, debug=True)



const express = require("express");
const multer = require("multer");
const axios = require("axios");
const app = express();
const upload = multer();

app.post("/analyze", upload.single("image"), async (req, res) => {
    try {
        const response = await axios.post("http://localhost:5001/predict", req.file.buffer, {
            headers: { "Content-Type": "multipart/form-data" },
        });
        res.json(response.data);
    } catch (error) {
        res.status(500).json({ error: "Error communicating with the AI model" });
    }
});

app.listen(5000, () => {
    console.log("Server running on http://localhost:5000");
});



import React, { useState } from "react";

function App() {
    const [emotion, setEmotion] = useState("No Data");

    const handleUpload = async (event) => {
        const file = event.target.files[0];
        const formData = new FormData();
        formData.append("image", file);

        const response = await fetch("http://localhost:5000/analyze", {
            method: "POST",
            body: formData,
        });
        const data = await response.json();
        setEmotion(data.emotions?.[0] || "No Face Detected");
    };

    return (
        <div style={{ textAlign: "center", marginTop: "20%" }}>
            <h1>AI-Based Stress Detection</h1>
            <input type="file" accept="image/*" onChange={handleUpload} />
            <p>Detected Emotion: <strong>{emotion}</strong></p>
        </div>
    );
}

export default App;

import React from "react";
import ReactDOM from "react-dom";
import App from "./App";

ReactDOM.render(<App />, document.getElementById("root"));
{
  "dependencies": {
    "react": "^17.0.2",
    "react-dom": "^17.0.2"
  }
}
